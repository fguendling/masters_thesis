\chapter{Fazit und Ausblick}
\label{chap5}

Ausgangsbasis dieser Arbeit war die Annahme, dass Entscheidungen zum Application-Portfolio-Management meist auf Expertenmeinungen und manuellen Prozessen basieren. Diese Entscheidungen können also sowohl ``papiergetrieben`` (was von Menschen elektronisch erstellte Dokumente einschließt) als auch unterstützt durch diverse Architektur-Tools getroffen werden. Grundlage für die Entscheidungen können Dokumentationen sein, die in Textform vorliegen. Die Dokumentationen können wertvolle Informationen enthalten. Die Extraktion der Informationen bzw. die Auswertung der Dokumente durch Menschen ist aber schwierig und zeitaufwändig. Ein hybrider Ansatz aus menschlicher und künstlicher Intelligenz wird daher angestrebt.

Die vorliegende Arbeit versuchte daher eine Verbindung zwischen den beiden Domänen IT-Governance und Maschinelles Lernen herzustellen. Untersucht werden sollte, welche ML-Verfahren für das APM von Bedeutung sein können. Es wurden datengestützte, praktische Verfahren auf ein dem IT-Management zuzuschreibendes Thema angewendet und evaluiert. IT-Governance wird dabei als Teilgebiet des IT-Managements betrachtet \cite[S. 6]{reiss}. Bevor die Evaluation von ML-Verfahren überhaupt durchgeführt werden konnte, mussten verschiedene Verfahren in einem vorhergehenden Schritt ausgewählt werden und von nicht-relevanten Verfahren getrennt werden. Zusätzlich war zu klären, mit welchen Fragestellungen sich das APM überhaupt beschäftigt.

Die Verfahren wurden alle in Python implementiert, da in der Sprache viele Bibliotheken für maschinelles Lernen zur Verfügung stehen. Diese Bibliotheken werden in vielen Tutorials und Beispielen verwendet. Die sorgfältige Aufbereitung bzw. das ordentliche Einlesen von Texten wurde in der praktischen Tätigkeit als Voraussetzung für den späteren Erfolg des Einsatzes von Machine-Learning-Verfahren identifiziert. Wenn etwa Texte nur zur Hälfte verarbeitet werden, Aufzählungen oder Tabellen ignoriert werden, oder statische Bestandteile wie das Datum der Veröffentlichung oder Seitennummern fälschlicherweise in die Verarbeitung aufgenommen werden, dann kann sich die Vorhersage eines ML-Verfahrens aufgrund dieser Fehler später als nicht zuverlässig herausstellen. Das bekannte Pareto-Prinzip kann hier Anwendung finden, indem von 80\% des Aufwands für Vorverarbeitung von Texten und lediglich 20\% für den Einsatz bzw. die Evaluation von ML-Verfahren ausgegangen werden kann. Die Trainingsdaten sollten außerdem die Daten, die später verarbeitet werden, möglichst gut repräsentieren. 

Als ungelöstes Problem verbleibt insbesondere die Extraktion von Informationen aus Bildern. Hierbei handelt es sich um eine andere Domäne als NLP. Auch Bilder können Träger von wichtigen Informationen sein, weshalb hier noch Potenzial zu Verbesserungen liegt. Wenn ausschließlich Texte betrachtet werden, dann gingen für das APM wichtige Informationen verloren.

Überwachte Verfahren des maschinellen Lernens sind problematisch für eine sehr spezielle Domäne wie das APM, da zunächst viel Aufwand in das Beschriften von Beispiel-Dokumenten/ -Abschnitten/ und/ oder -Sätzen investiert werden muss. Die Beschriftungen sollten von Experten durchgeführt werden. Es müssen Beschriftungen in ausreichender Menge gesammelt werden, da bei unbekannten neuen Dokumenten die Schätzungen sonst ungenaue Ergebnisse liefern. Unüberwachte Ansätze, wie bei der Verwendung von vortrainierten Modellen oder beim Topic-Modeling, benötigen keine Beschriftungen. Sie können daher als Alternative in Betracht gezogen werden, wenn der Aufwand für überwachte Verfahren als zu hoch eingeschätzt wird. 

Fast alle der untersuchten Anwendungsfälle können zu Klassifizierungsproblemen reduziert werden. Als Eingabe kommen verschiedene Ebenen in Frage: mehrere Dokumente auf einmal, einzelne Dokumente, einzelne Abschnitte oder auch einzelne Sätze. Die Verfahren, die hier evaluiert wurden, können demnach auch für andere Anwendungsfälle angepasst werden.

TF-IDF wurde als universelles Werkzeug zur Vorverarbeitung von Texten für verschiedene Anwendungsfälle identifiziert. Es ermöglicht die Bestimmung der Wichtigkeit einzelner Begriffe und kann daher für quasi alle Anwendungsfälle, die in dieser Arbeit beschrieben wurden, sinnvoll genutzt werden. Für vektorbasierte Ansätze gilt eine ähnliche Bedeutung. Auch diese Art der Vorverarbeitung ist unabhängig von Anwendungsfällen und sollte in Betracht gezogen, wenn mit Text gearbeitet werden soll. Transformer-Ansätze werden aktiv erforscht und sind daher für die Zukunft im Auge zu behalten. 
Aktuelle Transformer-Ansätze wie BERT oder GPT-3 sollen hier als vielversprechend im Bereich der künstlichen Intelligenz hervorgehoben werden.
